---
title: Sensitivity Calculation
---

## Analysis
Sensitivity scores were collected using the Fish Stock Climate Vulnerability Assessment Portal, and exported as a csv. Scores were calculated for each attribute and these scores were used to calculate a final exposure score for the species. Unlike exposure, and similar to the original analysis, a single value is produced for each species.  

### Attribute Scores
Attribute scores were calculated using a weighted average following Equation 1 in Morrison et al 2015. Briefly, the number of tallies in each of the four bins is multiplied by a weight, summed, and divided by the total number of tallies (which would be 5 scorers per species x 5 tallies per scorer = 25). The weights that correspond to each bin are: 

|Bin| Weight | 
|:---------:|:---------:|
| Low | 1   | 
| Medium | 2  | 
| High |  3 |  
| Very High | 4 |
: Bin Weights

The function `attribute.score` performs the weighted average. This function is based on code provided by the Tyler Loughran and the Atlantic Highly Migratory Species Management Division, Office of Sustainable Fisheries. The workflow is outlined below. 

### Total Sensitivity Scores
Following the original CVA methods, total sensitivity is calculated with a logic rule. This is the same logic rule used to calculate total exposure from individual variable exposure scores: 

|Overall Score| Numeric Score | Logic Rule |
|:---------:|:---------:|:---------:|
| Low | 1   |   All other scores  |
| Medium | 2  | 2 or more attributes >= 2.5   |  
| High | 3 |  2 or more attributes >= 3.0  |
| Very High | 4 | 3 or more attributes >= 3.5 |
: Logic Rule used to Calculate Total Species Sensitivity

The total sensitivity score is calculated using the `logic.rule` function.

### Workflow
#### Calculating Scores
A single function, `calculate.sensitivity`, combines both the attribute score calculation done by `attribute.score` and the total sensitivity score calculation done by `logic.rule` in a single function. This function is modeled on provided code from the Southeast Fisheries Science Center. 

```{r}
#| eval: false
data <-read.csv('expert_scores.csv') #raw sensitivity data from FSCVA Portal
species.data.list <- split(data, data$Stock.Name) #generate a list of data.frames, where each species has its own dedicated data frame of scores from all scorers in the list
species.sensitivity <- lapply(species.data.list, calculate.sensitivity, bootstrap = F) #calculate attribute scores and total sensitivity 
```
The resulting data.frame contains a row for each species scored, with columns containing the attribute scores and a total sensitivity score. 

#### Calculating Uncertainty
Uncertainty was quantified using the tally-based scoring system described above. Uncertainty was calculated by resampling the tallies with replacement across the four bins, and recalculating the weighted average attribute score, then the total sensitivity. Following the original CVA, uncertainty is represented as the proportion or percent of bootstrapped total sensitivity scores that match the expert-derived total scores. For the default number of iterations (10,000), this function takes just under a minute (~45 seconds) per species on a standard workstation. 

Both 'attribute.score' and 'logic.rule', and subsequently 'calculate.sensitivity' have the ability to also perform the bootstrap calculation. 
```{r}
#| eval: false
data <-read.csv('expert_scores.csv') #raw sensitivity data from FSCVA Portal
species.data.list <- split(data, data$Stock.Name) #generate a list of data.frames, where each species has its own dedicated data frame of scores from all scorers in the list
sensitivity.bootstrap <- lapply(species.data.list, calculate.sensitivity, bootstrap = T, samples = 10000) #calculate sensitivity with bootstrapping 
```
When `bootstrap = TRUE`, the resulting data.frame will have a number of rows equal to the number of `samples`, with each row representing one of the iterations. Columns will contain the attribute scores and total sensitivity score for that iteration. 

The function `bootstrap.certainty` calculates the final uncertainty value (AKA the proportion of bootstrap iterations that match the expert scores). This function will calculate the proportion of bootstrapped total sensitivity scores correspond to each possible score (1-4). If `match = TRUE`, then the corresponding proportion to the score derived from the expert tallies will be appended to the output from `calculate.sensitivity(bootstrap = TRUE)` as a column called `Certainty`. If `match = FALSE`, a vector containing the proportion of bootstrap scores that correspond to each possible total sensitivity score is returned.  

The entire workflow can be run using `lapply` and `mapply` functionality on the entire raw dataset from the FSCVA portal using only 6 lines of code: 
```{r}
#| eval: false
data <-read.csv('expert_scores.csv') #raw sensitivity data from FSCVA Portal
species.data.list <- split(data, data$Stock.Name) #generate a list of data.frames, where each species has its own dedicated data frame of scores from all scorers in the list
species.sensitivity <- lapply(species.data.list, calculate.sensitivity, bootstrap = F) #calculate attribute scores and total sensitivity
sensitivity.bootstrap <- lapply(species.data.list, calculate.sensitivity, bootstrap = T, samples = 10000) #calculate sensitivity with bootstrapping 
sensitivity.certainty <- mapply(bootstrap.certainty, sensitivity.bootstrap, species.sensitivity, SIMPLIFY = F) #note the use of mapply rather than lapply here since both inputs are lists
#since both input lists are use species.data.list, they will be in the same order
sensitivityDF <- do.call(rbind, sensitivity.certainty) #this combines the list of vectors into a data.frame
```

The resulting data.frame shows the scores for each attribute, plus the total sensitivity and corresponding certainty: 
```{r}
#| echo: false
sens <- read.csv('sensitivity1.0.csv')
head(sens)
```
